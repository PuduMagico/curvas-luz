{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "\n",
    "from cifar10 import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "tf.set_random_seed(1)\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "batch_size = 64\n",
    "cifar10 = CIFAR10(batch_size=batch_size, validation_proportion=0.1, augment_data=False, file='data_original.csv')\n",
    "\n",
    "SUMMARIES_DIR = './summaries/convnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model blocks\n",
    "def conv_layer(input_tensor, kernel_shape, layer_name):\n",
    "    # input_tensor b01c\n",
    "    # kernel_shape 01-in-out\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "                               initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    biases = tf.get_variable(\"biases\", [kernel_shape[3]],\n",
    "                             initializer=tf.constant_initializer(0.05))\n",
    "    \n",
    "    tf.summary.histogram(layer_name + \"/weights\", weights)\n",
    "    tf.summary.histogram(layer_name + \"/biases\", biases)\n",
    "    \n",
    "    # Other options are to use He et. al init. for weights and 0.01 \n",
    "    # to init. biases.\n",
    "    conv = tf.nn.conv2d(input_tensor, weights, \n",
    "                       strides = [1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "def fc_layer(input_tensor, weights_shape, layer_name):\n",
    "    # weights_shape in-out\n",
    "    weights = tf.get_variable(\"weights\", weights_shape,\n",
    "                              initializer = tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(\"biases\", [weights_shape[1]],\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "    tf.summary.histogram(layer_name + \"/weights\", weights)\n",
    "    tf.summary.histogram(layer_name + \"/biases\", biases)\n",
    "    mult_out = tf.matmul(input_tensor, weights)\n",
    "    return tf.nn.relu(mult_out+biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_input = tf.placeholder(tf.float32, name='model_input', \n",
    "                             shape=(batch_size,1,200,1))\n",
    "tf.summary.image('input', model_input, 10)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='dropout_prob', shape=())\n",
    "\n",
    "target = tf.placeholder(tf.float32, name='target', shape=(batch_size, 9))\n",
    "\n",
    " # Reshape tensor to MLP\n",
    "first_layer_input = tf.reshape(model_input, [-1,200], name='first_layer_input')\n",
    "# First layer\n",
    "layer_name = 'fc1'\n",
    "with tf.variable_scope(layer_name):\n",
    "    fc1_out = fc_layer(first_layer_input, [200, 150], layer_name)\n",
    "fc1_out_drop = tf.nn.dropout(fc1_out, keep_prob)\n",
    "# Second layer\n",
    "layer_name = 'fc2'\n",
    "with tf.variable_scope(layer_name):\n",
    "    fc2_out = fc_layer(fc1_out_drop, [150, 100],layer_name)\n",
    "fc2_out_drop = tf.nn.dropout(fc2_out, keep_prob)\n",
    "#Third Layer\n",
    "with tf.variable_scope(layer_name):\n",
    "    fc3_out = fc_layer(fc2_out_drop, [100,50], layer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pool2_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d274f6a97622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool2_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pool2_out' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with tf.name_scope('loss_function'):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=model_output, labels=target,\n",
    "                                           name='cross_entropy'))\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    grads_vars = optimizer.compute_gradients(cross_entropy)\n",
    "    optimizer.apply_gradients(grads_vars)\n",
    "    train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# Metrics\n",
    "correct_prediction = tf.equal(tf.argmax(model_output, 1),\n",
    "                             tf.argmax(target, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Useful training functions\n",
    "def validate():\n",
    "    batches = cifar10.getValidationSet(asBatches=True)\n",
    "    accs = []\n",
    "    for batch in batches:\n",
    "        data, labels = batch\n",
    "        acc = sess.run(accuracy,\n",
    "                       feed_dict={\n",
    "                model_input: data,\n",
    "                target: labels,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "        accs.append(acc)\n",
    "    mean_acc = np.array(accs).mean()\n",
    "    summary = sess.run(merged,\n",
    "                       feed_dict={\n",
    "                model_input: data,\n",
    "                target: labels,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "    return summary, mean_acc\n",
    "def test():\n",
    "    batches = cifar10.getTestSet(asBatches=True)\n",
    "    accs = []\n",
    "    for batch in batches:\n",
    "        data, labels = batch\n",
    "        acc = sess.run(accuracy,\n",
    "                       feed_dict={\n",
    "                model_input: data,\n",
    "                target: labels,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "        accs.append(acc)\n",
    "    mean_acc = np.array(accs).mean()\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable variables\n",
      "fc1/weights:0\n",
      "fc1/biases:0\n",
      "fc2/weights:0\n",
      "fc2/biases:0\n",
      "Epoch 0, training loss 1.996196, accuracy 0.375000\n",
      "Validation accuracy 0.268750\n",
      "Time elapsed 0.0008004546165466308 minutes\n",
      "Epoch 1, training loss 1.807402, accuracy 0.359375\n",
      "Validation accuracy 0.333333\n",
      "Time elapsed 0.0043549736340840655 minutes\n",
      "Epoch 2, training loss 1.876827, accuracy 0.265625\n",
      "Validation accuracy 0.280208\n",
      "Time elapsed 0.007988675435384115 minutes\n",
      "Epoch 3, training loss 1.573488, accuracy 0.406250\n",
      "Validation accuracy 0.298958\n",
      "Time elapsed 0.011626386642456054 minutes\n",
      "Epoch 4, training loss 1.668158, accuracy 0.343750\n",
      "Validation accuracy 0.361458\n",
      "Time elapsed 0.015266068776448568 minutes\n",
      "Epoch 5, training loss 1.549179, accuracy 0.359375\n",
      "Validation accuracy 0.418750\n",
      "Time elapsed 0.018986809253692626 minutes\n",
      "Epoch 6, training loss 1.638924, accuracy 0.328125\n",
      "Validation accuracy 0.412500\n",
      "Time elapsed 0.022706433137257894 minutes\n",
      "Epoch 7, training loss 1.555921, accuracy 0.421875\n",
      "Validation accuracy 0.382292\n",
      "Time elapsed 0.026298379898071288 minutes\n",
      "Epoch 8, training loss 1.520918, accuracy 0.406250\n",
      "Validation accuracy 0.325000\n",
      "Time elapsed 0.029928783575693767 minutes\n",
      "Epoch 9, training loss 1.677122, accuracy 0.343750\n",
      "Validation accuracy 0.422917\n",
      "Time elapsed 0.034976065158843994 minutes\n",
      "Epoch 10, training loss 1.798318, accuracy 0.468750\n",
      "Validation accuracy 0.438542\n",
      "Time elapsed 0.04007037878036499 minutes\n",
      "Epoch 11, training loss 1.493295, accuracy 0.468750\n",
      "Validation accuracy 0.452083\n",
      "Time elapsed 0.0438526709874471 minutes\n",
      "Epoch 12, training loss 1.753753, accuracy 0.421875\n",
      "Validation accuracy 0.447917\n",
      "Time elapsed 0.04749335845311483 minutes\n",
      "Epoch 13, training loss 1.474693, accuracy 0.390625\n",
      "Validation accuracy 0.458333\n",
      "Time elapsed 0.05148742198944092 minutes\n",
      "Epoch 14, training loss 1.655476, accuracy 0.468750\n",
      "Validation accuracy 0.470833\n",
      "Time elapsed 0.0551043709119161 minutes\n",
      "Epoch 15, training loss 1.353088, accuracy 0.484375\n",
      "Validation accuracy 0.477083\n",
      "Time elapsed 0.059000126520792645 minutes\n",
      "Epoch 16, training loss 1.266917, accuracy 0.656250\n",
      "Validation accuracy 0.465625\n",
      "Time elapsed 0.06367689371109009 minutes\n",
      "Epoch 17, training loss 1.405021, accuracy 0.453125\n",
      "Validation accuracy 0.486458\n",
      "Time elapsed 0.06775941848754882 minutes\n",
      "Epoch 18, training loss 1.430172, accuracy 0.437500\n",
      "Validation accuracy 0.469792\n",
      "Time elapsed 0.07236071825027465 minutes\n",
      "Epoch 19, training loss 1.385833, accuracy 0.593750\n",
      "Validation accuracy 0.482292\n",
      "Time elapsed 0.07681588331858318 minutes\n",
      "Epoch 20, training loss 1.336971, accuracy 0.484375\n",
      "Validation accuracy 0.496875\n",
      "Time elapsed 0.08205100695292154 minutes\n",
      "Epoch 21, training loss 1.369435, accuracy 0.500000\n",
      "Validation accuracy 0.490625\n",
      "Time elapsed 0.08624971310297648 minutes\n",
      "Epoch 22, training loss 1.195449, accuracy 0.609375\n",
      "Validation accuracy 0.514583\n",
      "Time elapsed 0.09073991378148397 minutes\n",
      "Epoch 23, training loss 1.169872, accuracy 0.578125\n",
      "Validation accuracy 0.514583\n",
      "Time elapsed 0.09525122642517089 minutes\n",
      "Epoch 24, training loss 1.160199, accuracy 0.593750\n",
      "Validation accuracy 0.500000\n",
      "Time elapsed 0.09957414468129476 minutes\n",
      "Epoch 25, training loss 1.432634, accuracy 0.500000\n",
      "Validation accuracy 0.523958\n",
      "Time elapsed 0.10450541575749715 minutes\n",
      "Epoch 26, training loss 1.223083, accuracy 0.500000\n",
      "Validation accuracy 0.527083\n",
      "Time elapsed 0.10876275698343912 minutes\n",
      "Epoch 27, training loss 1.334064, accuracy 0.484375\n",
      "Validation accuracy 0.495833\n",
      "Time elapsed 0.11297972997029622 minutes\n",
      "Epoch 28, training loss 1.134760, accuracy 0.593750\n",
      "Validation accuracy 0.501042\n",
      "Time elapsed 0.11710325876871745 minutes\n",
      "Epoch 29, training loss 1.279747, accuracy 0.453125\n",
      "Validation accuracy 0.516667\n",
      "Time elapsed 0.12114628156026204 minutes\n",
      "Epoch 30, training loss 1.200092, accuracy 0.546875\n",
      "Validation accuracy 0.514583\n",
      "Time elapsed 0.12528103590011597 minutes\n",
      "Epoch 31, training loss 1.206024, accuracy 0.500000\n",
      "Validation accuracy 0.527083\n",
      "Time elapsed 0.12951120138168334 minutes\n",
      "Epoch 32, training loss 1.442977, accuracy 0.468750\n",
      "Validation accuracy 0.536458\n",
      "Time elapsed 0.13367937008539835 minutes\n",
      "Epoch 33, training loss 1.370841, accuracy 0.453125\n",
      "Validation accuracy 0.521875\n",
      "Time elapsed 0.13754984935124714 minutes\n",
      "Epoch 34, training loss 1.446537, accuracy 0.500000\n",
      "Validation accuracy 0.512500\n",
      "Time elapsed 0.14137238264083862 minutes\n",
      "Epoch 35, training loss 1.331527, accuracy 0.453125\n",
      "Validation accuracy 0.535417\n",
      "Time elapsed 0.14490600426991782 minutes\n",
      "Epoch 36, training loss 1.199628, accuracy 0.578125\n",
      "Validation accuracy 0.529167\n",
      "Time elapsed 0.14900991121927898 minutes\n",
      "Epoch 37, training loss 1.232577, accuracy 0.609375\n",
      "Validation accuracy 0.536458\n",
      "Time elapsed 0.15256837606430054 minutes\n",
      "Epoch 38, training loss 1.214725, accuracy 0.515625\n",
      "Validation accuracy 0.512500\n",
      "Time elapsed 0.15613694190979005 minutes\n",
      "Epoch 39, training loss 1.228514, accuracy 0.656250\n",
      "Validation accuracy 0.536458\n",
      "Time elapsed 0.15951300859451295 minutes\n",
      "Epoch 40, training loss 1.343342, accuracy 0.500000\n",
      "Validation accuracy 0.520833\n",
      "Time elapsed 0.163229501247406 minutes\n",
      "Epoch 41, training loss 1.271988, accuracy 0.515625\n",
      "Validation accuracy 0.537500\n",
      "Time elapsed 0.16677279869715372 minutes\n",
      "Epoch 42, training loss 1.475483, accuracy 0.546875\n",
      "Validation accuracy 0.522917\n",
      "Time elapsed 0.17027804056803386 minutes\n",
      "Epoch 43, training loss 1.210107, accuracy 0.562500\n",
      "Validation accuracy 0.559375\n",
      "Time elapsed 0.17380897601445516 minutes\n",
      "Epoch 44, training loss 1.183001, accuracy 0.578125\n",
      "Validation accuracy 0.550000\n",
      "Time elapsed 0.17727102041244508 minutes\n",
      "Epoch 45, training loss 1.354402, accuracy 0.468750\n",
      "Validation accuracy 0.569792\n",
      "Time elapsed 0.18086816469828287 minutes\n",
      "Epoch 46, training loss 1.291150, accuracy 0.656250\n",
      "Validation accuracy 0.547917\n",
      "Time elapsed 0.18444873889287314 minutes\n",
      "Epoch 47, training loss 1.175410, accuracy 0.546875\n",
      "Validation accuracy 0.550000\n",
      "Time elapsed 0.1878946622212728 minutes\n",
      "Epoch 48, training loss 1.132257, accuracy 0.609375\n",
      "Validation accuracy 0.558333\n",
      "Time elapsed 0.19152549505233765 minutes\n",
      "Epoch 49, training loss 1.150634, accuracy 0.593750\n",
      "Validation accuracy 0.555208\n",
      "Time elapsed 0.19504251082738241 minutes\n",
      "Epoch 50, training loss 1.203206, accuracy 0.578125\n",
      "Validation accuracy 0.555208\n",
      "Time elapsed 0.19878294467926025 minutes\n",
      "Epoch 51, training loss 1.021914, accuracy 0.609375\n",
      "Validation accuracy 0.543750\n",
      "Time elapsed 0.20214573542277017 minutes\n",
      "Epoch 52, training loss 1.389833, accuracy 0.421875\n",
      "Validation accuracy 0.528125\n",
      "Time elapsed 0.20576743284861246 minutes\n",
      "Epoch 53, training loss 1.109820, accuracy 0.562500\n",
      "Validation accuracy 0.583333\n",
      "Time elapsed 0.20942377646764118 minutes\n",
      "Epoch 54, training loss 1.156069, accuracy 0.562500\n",
      "Validation accuracy 0.571875\n",
      "Time elapsed 0.2127366820971171 minutes\n",
      "Epoch 55, training loss 1.684848, accuracy 0.437500\n",
      "Validation accuracy 0.550000\n",
      "Time elapsed 0.21632795731226603 minutes\n",
      "Epoch 56, training loss 1.280314, accuracy 0.515625\n",
      "Validation accuracy 0.526042\n",
      "Time elapsed 0.2203237732251485 minutes\n",
      "Epoch 57, training loss 1.148300, accuracy 0.578125\n",
      "Validation accuracy 0.556250\n",
      "Time elapsed 0.22385044892628989 minutes\n",
      "Epoch 58, training loss 1.085168, accuracy 0.546875\n",
      "Validation accuracy 0.552083\n",
      "Time elapsed 0.22752339839935304 minutes\n",
      "Epoch 59, training loss 1.262653, accuracy 0.578125\n",
      "Validation accuracy 0.546875\n",
      "Time elapsed 0.23120177984237672 minutes\n",
      "Epoch 60, training loss 1.243349, accuracy 0.593750\n",
      "Validation accuracy 0.577083\n",
      "Time elapsed 0.23527212540308634 minutes\n",
      "Epoch 61, training loss 1.034266, accuracy 0.625000\n",
      "Validation accuracy 0.543750\n",
      "Time elapsed 0.23918091058731078 minutes\n",
      "Epoch 62, training loss 0.919361, accuracy 0.703125\n",
      "Validation accuracy 0.572917\n",
      "Time elapsed 0.2430062731107076 minutes\n",
      "Epoch 63, training loss 1.200432, accuracy 0.593750\n",
      "Validation accuracy 0.573958\n",
      "Time elapsed 0.24697811603546144 minutes\n",
      "Epoch 64, training loss 1.260327, accuracy 0.578125\n",
      "Validation accuracy 0.579167\n",
      "Time elapsed 0.25069578488667804 minutes\n",
      "Epoch 65, training loss 1.057280, accuracy 0.593750\n",
      "Validation accuracy 0.563542\n",
      "Time elapsed 0.25452622175216677 minutes\n",
      "Epoch 66, training loss 1.166240, accuracy 0.515625\n",
      "Validation accuracy 0.571875\n",
      "Time elapsed 0.2582101861635844 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, training loss 1.165938, accuracy 0.593750\n",
      "Validation accuracy 0.578125\n",
      "Time elapsed 0.26175321340560914 minutes\n",
      "Epoch 68, training loss 1.257999, accuracy 0.515625\n",
      "Validation accuracy 0.570833\n",
      "Time elapsed 0.26563080549240115 minutes\n",
      "Epoch 69, training loss 1.115557, accuracy 0.593750\n",
      "Validation accuracy 0.577083\n",
      "Time elapsed 0.26926979621251423 minutes\n",
      "Epoch 70, training loss 1.474542, accuracy 0.437500\n",
      "Validation accuracy 0.579167\n",
      "Time elapsed 0.2730587085088094 minutes\n",
      "Epoch 71, training loss 1.103183, accuracy 0.625000\n",
      "Validation accuracy 0.577083\n",
      "Time elapsed 0.2765313227971395 minutes\n",
      "Epoch 72, training loss 0.962397, accuracy 0.656250\n",
      "Validation accuracy 0.582292\n",
      "Time elapsed 0.2800714174906413 minutes\n",
      "Epoch 73, training loss 1.095150, accuracy 0.515625\n",
      "Validation accuracy 0.580208\n",
      "Time elapsed 0.28366639216740924 minutes\n",
      "Epoch 74, training loss 1.268079, accuracy 0.531250\n",
      "Validation accuracy 0.559375\n",
      "Time elapsed 0.28749885559082033 minutes\n",
      "Epoch 75, training loss 0.961113, accuracy 0.625000\n",
      "Validation accuracy 0.583333\n",
      "Time elapsed 0.29135906298955283 minutes\n",
      "Epoch 76, training loss 1.029026, accuracy 0.703125\n",
      "Validation accuracy 0.568750\n",
      "Time elapsed 0.29508817195892334 minutes\n",
      "Epoch 77, training loss 1.131397, accuracy 0.625000\n",
      "Validation accuracy 0.580208\n",
      "Time elapsed 0.2988633394241333 minutes\n",
      "Epoch 78, training loss 1.166891, accuracy 0.546875\n",
      "Validation accuracy 0.586458\n",
      "Time elapsed 0.3026384234428406 minutes\n",
      "Epoch 79, training loss 1.317685, accuracy 0.484375\n",
      "Validation accuracy 0.587500\n",
      "Time elapsed 0.3063439170519511 minutes\n",
      "Epoch 80, training loss 1.057201, accuracy 0.593750\n",
      "Validation accuracy 0.580208\n",
      "Time elapsed 0.31026198863983157 minutes\n",
      "Epoch 81, training loss 1.052670, accuracy 0.625000\n",
      "Validation accuracy 0.562500\n",
      "Time elapsed 0.3140102744102478 minutes\n",
      "Epoch 82, training loss 1.226391, accuracy 0.500000\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.31781735420227053 minutes\n",
      "Epoch 83, training loss 1.061535, accuracy 0.625000\n",
      "Validation accuracy 0.592708\n",
      "Time elapsed 0.3219302773475647 minutes\n",
      "Epoch 84, training loss 1.158026, accuracy 0.609375\n",
      "Validation accuracy 0.580208\n",
      "Time elapsed 0.3257574637730916 minutes\n",
      "Epoch 85, training loss 1.170676, accuracy 0.593750\n",
      "Validation accuracy 0.590625\n",
      "Time elapsed 0.32983668247858683 minutes\n",
      "Epoch 86, training loss 1.219978, accuracy 0.562500\n",
      "Validation accuracy 0.580208\n",
      "Time elapsed 0.33362387418746947 minutes\n",
      "Epoch 87, training loss 1.135300, accuracy 0.515625\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.33713384469350177 minutes\n",
      "Epoch 88, training loss 1.178911, accuracy 0.578125\n",
      "Validation accuracy 0.540625\n",
      "Time elapsed 0.34075971047083536 minutes\n",
      "Epoch 89, training loss 1.208207, accuracy 0.468750\n",
      "Validation accuracy 0.601042\n",
      "Time elapsed 0.344282599290212 minutes\n",
      "Epoch 90, training loss 1.282276, accuracy 0.562500\n",
      "Validation accuracy 0.588542\n",
      "Time elapsed 0.34808589617411295 minutes\n",
      "Epoch 91, training loss 1.037788, accuracy 0.609375\n",
      "Validation accuracy 0.602083\n",
      "Time elapsed 0.3516899148623149 minutes\n",
      "Epoch 92, training loss 1.029687, accuracy 0.593750\n",
      "Validation accuracy 0.593750\n",
      "Time elapsed 0.35550063451131186 minutes\n",
      "Epoch 93, training loss 1.173670, accuracy 0.640625\n",
      "Validation accuracy 0.591667\n",
      "Time elapsed 0.35930149952570595 minutes\n",
      "Epoch 94, training loss 1.089679, accuracy 0.531250\n",
      "Validation accuracy 0.589583\n",
      "Time elapsed 0.36299126545588173 minutes\n",
      "Epoch 95, training loss 1.274839, accuracy 0.515625\n",
      "Validation accuracy 0.604167\n",
      "Time elapsed 0.3667103131612142 minutes\n",
      "Epoch 96, training loss 1.179073, accuracy 0.531250\n",
      "Validation accuracy 0.611458\n",
      "Time elapsed 0.3706602732340495 minutes\n",
      "Epoch 97, training loss 1.122953, accuracy 0.578125\n",
      "Validation accuracy 0.591667\n",
      "Time elapsed 0.37426275412241616 minutes\n",
      "Epoch 98, training loss 0.959069, accuracy 0.640625\n",
      "Validation accuracy 0.596875\n",
      "Time elapsed 0.37817450761795046 minutes\n",
      "Epoch 99, training loss 1.093454, accuracy 0.546875\n",
      "Validation accuracy 0.588542\n",
      "Time elapsed 0.38187819719314575 minutes\n",
      "Epoch 100, training loss 1.129350, accuracy 0.546875\n",
      "Validation accuracy 0.583333\n",
      "Time elapsed 0.3857442378997803 minutes\n",
      "Epoch 101, training loss 1.056996, accuracy 0.578125\n",
      "Validation accuracy 0.589583\n",
      "Time elapsed 0.389607834815979 minutes\n",
      "Epoch 102, training loss 0.949251, accuracy 0.656250\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.3938376784324646 minutes\n",
      "Epoch 103, training loss 1.202922, accuracy 0.468750\n",
      "Validation accuracy 0.566667\n",
      "Time elapsed 0.39750037988026937 minutes\n",
      "Epoch 104, training loss 1.178592, accuracy 0.625000\n",
      "Validation accuracy 0.601042\n",
      "Time elapsed 0.40116910139719647 minutes\n",
      "Epoch 105, training loss 1.383666, accuracy 0.531250\n",
      "Validation accuracy 0.585417\n",
      "Time elapsed 0.404783038298289 minutes\n",
      "Epoch 106, training loss 1.133675, accuracy 0.578125\n",
      "Validation accuracy 0.597917\n",
      "Time elapsed 0.4085319717725118 minutes\n",
      "Epoch 107, training loss 0.977908, accuracy 0.656250\n",
      "Validation accuracy 0.594792\n",
      "Time elapsed 0.41261523564656577 minutes\n",
      "Epoch 108, training loss 1.132137, accuracy 0.578125\n",
      "Validation accuracy 0.597917\n",
      "Time elapsed 0.4164384126663208 minutes\n",
      "Epoch 109, training loss 1.018820, accuracy 0.562500\n",
      "Validation accuracy 0.579167\n",
      "Time elapsed 0.42009927829106647 minutes\n",
      "Epoch 110, training loss 1.245726, accuracy 0.531250\n",
      "Validation accuracy 0.581250\n",
      "Time elapsed 0.4236786405245463 minutes\n",
      "Epoch 111, training loss 1.205302, accuracy 0.468750\n",
      "Validation accuracy 0.597917\n",
      "Time elapsed 0.4275038480758667 minutes\n",
      "Epoch 112, training loss 1.096997, accuracy 0.609375\n",
      "Validation accuracy 0.591667\n",
      "Time elapsed 0.43130558729171753 minutes\n",
      "Epoch 113, training loss 0.890421, accuracy 0.640625\n",
      "Validation accuracy 0.580208\n",
      "Time elapsed 0.43505065043767294 minutes\n",
      "Epoch 114, training loss 1.022511, accuracy 0.734375\n",
      "Validation accuracy 0.592708\n",
      "Time elapsed 0.4386354684829712 minutes\n",
      "Epoch 115, training loss 0.832741, accuracy 0.625000\n",
      "Validation accuracy 0.596875\n",
      "Time elapsed 0.44217632214228314 minutes\n",
      "Epoch 116, training loss 1.142828, accuracy 0.640625\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.44595890045166015 minutes\n",
      "Epoch 117, training loss 1.051541, accuracy 0.656250\n",
      "Validation accuracy 0.592708\n",
      "Time elapsed 0.4494244813919067 minutes\n",
      "Epoch 118, training loss 1.042628, accuracy 0.578125\n",
      "Validation accuracy 0.607292\n",
      "Time elapsed 0.4529060522715251 minutes\n",
      "Epoch 119, training loss 0.878825, accuracy 0.718750\n",
      "Validation accuracy 0.594792\n",
      "Time elapsed 0.4565445423126221 minutes\n",
      "Epoch 120, training loss 1.114942, accuracy 0.578125\n",
      "Validation accuracy 0.607292\n",
      "Time elapsed 0.4600348949432373 minutes\n",
      "Epoch 121, training loss 1.046103, accuracy 0.578125\n",
      "Validation accuracy 0.607292\n",
      "Time elapsed 0.46352081298828124 minutes\n",
      "Epoch 122, training loss 1.125050, accuracy 0.546875\n",
      "Validation accuracy 0.607292\n",
      "Time elapsed 0.46708430449167887 minutes\n",
      "Epoch 123, training loss 0.939504, accuracy 0.656250\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.47060089906056723 minutes\n",
      "Epoch 124, training loss 1.002091, accuracy 0.718750\n",
      "Validation accuracy 0.608333\n",
      "Time elapsed 0.4743471384048462 minutes\n",
      "Epoch 125, training loss 1.003207, accuracy 0.609375\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.47783195972442627 minutes\n",
      "Epoch 126, training loss 0.787396, accuracy 0.687500\n",
      "Validation accuracy 0.615625\n",
      "Time elapsed 0.48139676650365193 minutes\n",
      "Epoch 127, training loss 1.002923, accuracy 0.625000\n",
      "Validation accuracy 0.594792\n",
      "Time elapsed 0.48519324461619057 minutes\n",
      "Epoch 128, training loss 1.148969, accuracy 0.515625\n",
      "Validation accuracy 0.629167\n",
      "Time elapsed 0.4889542857805888 minutes\n",
      "Epoch 129, training loss 0.926835, accuracy 0.640625\n",
      "Validation accuracy 0.597917\n",
      "Time elapsed 0.4924568136533101 minutes\n",
      "Epoch 130, training loss 1.157534, accuracy 0.593750\n",
      "Validation accuracy 0.592708\n",
      "Time elapsed 0.4961323102315267 minutes\n",
      "Epoch 131, training loss 1.047100, accuracy 0.531250\n",
      "Validation accuracy 0.602083\n",
      "Time elapsed 0.49972943862279257 minutes\n",
      "Epoch 132, training loss 1.144892, accuracy 0.578125\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.503812599182129 minutes\n",
      "Epoch 133, training loss 1.104872, accuracy 0.562500\n",
      "Validation accuracy 0.581250\n",
      "Time elapsed 0.5073739171028138 minutes\n",
      "Epoch 134, training loss 1.011253, accuracy 0.625000\n",
      "Validation accuracy 0.579167\n",
      "Time elapsed 0.5112486521402995 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135, training loss 1.051813, accuracy 0.531250\n",
      "Validation accuracy 0.613542\n",
      "Time elapsed 0.5151730219523112 minutes\n",
      "Epoch 136, training loss 1.085293, accuracy 0.531250\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.5188013394673665 minutes\n",
      "Epoch 137, training loss 1.240729, accuracy 0.515625\n",
      "Validation accuracy 0.607292\n",
      "Time elapsed 0.5222923994064331 minutes\n",
      "Epoch 138, training loss 1.207445, accuracy 0.484375\n",
      "Validation accuracy 0.596875\n",
      "Time elapsed 0.5262560526529948 minutes\n",
      "Epoch 139, training loss 0.979375, accuracy 0.703125\n",
      "Validation accuracy 0.589583\n",
      "Time elapsed 0.5300336639086406 minutes\n",
      "Epoch 140, training loss 1.043628, accuracy 0.531250\n",
      "Validation accuracy 0.596875\n",
      "Time elapsed 0.5338499426841736 minutes\n",
      "Epoch 141, training loss 1.136081, accuracy 0.531250\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.537489120165507 minutes\n",
      "Epoch 142, training loss 0.985829, accuracy 0.500000\n",
      "Validation accuracy 0.611458\n",
      "Time elapsed 0.5412084857622782 minutes\n",
      "Epoch 143, training loss 1.065309, accuracy 0.656250\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.5448552052179972 minutes\n",
      "Epoch 144, training loss 1.144335, accuracy 0.593750\n",
      "Validation accuracy 0.610417\n",
      "Time elapsed 0.5487601319948833 minutes\n",
      "Epoch 145, training loss 0.914947, accuracy 0.656250\n",
      "Validation accuracy 0.611458\n",
      "Time elapsed 0.552522603670756 minutes\n",
      "Epoch 146, training loss 1.169025, accuracy 0.609375\n",
      "Validation accuracy 0.585417\n",
      "Time elapsed 0.5564651409784953 minutes\n",
      "Epoch 147, training loss 1.058501, accuracy 0.562500\n",
      "Validation accuracy 0.562500\n",
      "Time elapsed 0.5600938399632772 minutes\n",
      "Epoch 148, training loss 1.106923, accuracy 0.593750\n",
      "Validation accuracy 0.626042\n",
      "Time elapsed 0.5637864549954732 minutes\n",
      "Epoch 149, training loss 1.051013, accuracy 0.515625\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.5676976084709168 minutes\n",
      "Epoch 150, training loss 0.952169, accuracy 0.687500\n",
      "Validation accuracy 0.611458\n",
      "Time elapsed 0.5713327368100484 minutes\n",
      "Epoch 151, training loss 1.072421, accuracy 0.656250\n",
      "Validation accuracy 0.612500\n",
      "Time elapsed 0.5747562289237976 minutes\n",
      "Epoch 152, training loss 0.951396, accuracy 0.593750\n",
      "Validation accuracy 0.611458\n",
      "Time elapsed 0.5783730904261272 minutes\n",
      "Epoch 153, training loss 0.979874, accuracy 0.562500\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.582491135597229 minutes\n",
      "Epoch 154, training loss 1.122758, accuracy 0.625000\n",
      "Validation accuracy 0.635417\n",
      "Time elapsed 0.5860573371251424 minutes\n",
      "Epoch 155, training loss 1.209853, accuracy 0.656250\n",
      "Validation accuracy 0.587500\n",
      "Time elapsed 0.5896609425544739 minutes\n",
      "Epoch 156, training loss 1.073274, accuracy 0.593750\n",
      "Validation accuracy 0.613542\n",
      "Time elapsed 0.5934060176213583 minutes\n",
      "Epoch 157, training loss 0.945417, accuracy 0.671875\n",
      "Validation accuracy 0.607292\n",
      "Time elapsed 0.5968610286712647 minutes\n",
      "Epoch 158, training loss 1.018507, accuracy 0.656250\n",
      "Validation accuracy 0.626042\n",
      "Time elapsed 0.6004489898681641 minutes\n",
      "Epoch 159, training loss 1.151128, accuracy 0.609375\n",
      "Validation accuracy 0.603125\n",
      "Time elapsed 0.6042087237040202 minutes\n",
      "Epoch 160, training loss 1.215146, accuracy 0.562500\n",
      "Validation accuracy 0.583333\n",
      "Time elapsed 0.6078181425730388 minutes\n",
      "Epoch 161, training loss 0.784079, accuracy 0.703125\n",
      "Validation accuracy 0.608333\n",
      "Time elapsed 0.6115813970565795 minutes\n",
      "Epoch 162, training loss 1.110964, accuracy 0.609375\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.6153868595759074 minutes\n",
      "Epoch 163, training loss 1.193573, accuracy 0.593750\n",
      "Validation accuracy 0.614583\n",
      "Time elapsed 0.6190694014231364 minutes\n",
      "Epoch 164, training loss 1.214090, accuracy 0.500000\n",
      "Validation accuracy 0.610417\n",
      "Time elapsed 0.6228269179662068 minutes\n",
      "Epoch 165, training loss 1.042438, accuracy 0.656250\n",
      "Validation accuracy 0.632292\n",
      "Time elapsed 0.6265100836753845 minutes\n",
      "Epoch 166, training loss 0.955057, accuracy 0.640625\n",
      "Validation accuracy 0.585417\n",
      "Time elapsed 0.6303395509719849 minutes\n",
      "Epoch 167, training loss 0.895000, accuracy 0.671875\n",
      "Validation accuracy 0.603125\n",
      "Time elapsed 0.6339983264605205 minutes\n",
      "Epoch 168, training loss 1.082510, accuracy 0.640625\n",
      "Validation accuracy 0.614583\n",
      "Time elapsed 0.637739892800649 minutes\n",
      "Epoch 169, training loss 1.298447, accuracy 0.515625\n",
      "Validation accuracy 0.617708\n",
      "Time elapsed 0.6414420564969381 minutes\n",
      "Epoch 170, training loss 1.113311, accuracy 0.500000\n",
      "Validation accuracy 0.613542\n",
      "Time elapsed 0.6451178391774496 minutes\n",
      "Epoch 171, training loss 1.087187, accuracy 0.640625\n",
      "Validation accuracy 0.596875\n",
      "Time elapsed 0.6492567340532939 minutes\n",
      "Epoch 172, training loss 1.039162, accuracy 0.640625\n",
      "Validation accuracy 0.626042\n",
      "Time elapsed 0.6532683412233988 minutes\n",
      "Epoch 173, training loss 0.978680, accuracy 0.656250\n",
      "Validation accuracy 0.601042\n",
      "Time elapsed 0.6570978442827861 minutes\n",
      "Epoch 174, training loss 0.878354, accuracy 0.640625\n",
      "Validation accuracy 0.589583\n",
      "Time elapsed 0.6606353282928467 minutes\n",
      "Epoch 175, training loss 1.052800, accuracy 0.578125\n",
      "Validation accuracy 0.606250\n",
      "Time elapsed 0.6642343680063884 minutes\n",
      "Epoch 176, training loss 0.875399, accuracy 0.671875\n",
      "Validation accuracy 0.582292\n",
      "Time elapsed 0.667660657564799 minutes\n",
      "Epoch 177, training loss 1.083512, accuracy 0.718750\n",
      "Validation accuracy 0.608333\n",
      "Time elapsed 0.6712909817695618 minutes\n",
      "Epoch 178, training loss 1.085354, accuracy 0.593750\n",
      "Validation accuracy 0.625000\n",
      "Time elapsed 0.6749701142311096 minutes\n",
      "Epoch 179, training loss 0.907872, accuracy 0.609375\n",
      "Validation accuracy 0.603125\n",
      "Time elapsed 0.6785803039868673 minutes\n",
      "Epoch 180, training loss 0.906929, accuracy 0.625000\n",
      "Validation accuracy 0.616667\n",
      "Time elapsed 0.682380477587382 minutes\n",
      "Epoch 181, training loss 1.088623, accuracy 0.546875\n",
      "Validation accuracy 0.618750\n",
      "Time elapsed 0.686210302511851 minutes\n",
      "Epoch 182, training loss 1.185909, accuracy 0.562500\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.6900724291801452 minutes\n",
      "Epoch 183, training loss 0.912363, accuracy 0.687500\n",
      "Validation accuracy 0.620833\n",
      "Time elapsed 0.6937164425849914 minutes\n",
      "Epoch 184, training loss 1.048082, accuracy 0.625000\n",
      "Validation accuracy 0.606250\n",
      "Time elapsed 0.6971214413642883 minutes\n",
      "Epoch 185, training loss 1.002138, accuracy 0.593750\n",
      "Validation accuracy 0.598958\n",
      "Time elapsed 0.7007381319999695 minutes\n",
      "Epoch 186, training loss 1.158879, accuracy 0.593750\n",
      "Validation accuracy 0.582292\n",
      "Time elapsed 0.7041426817576091 minutes\n",
      "Epoch 187, training loss 1.102894, accuracy 0.546875\n",
      "Validation accuracy 0.615625\n",
      "Time elapsed 0.7076678077379862 minutes\n",
      "Epoch 188, training loss 1.035297, accuracy 0.531250\n",
      "Validation accuracy 0.593750\n",
      "Time elapsed 0.7113436063130697 minutes\n",
      "Epoch 189, training loss 1.114266, accuracy 0.640625\n",
      "Validation accuracy 0.603125\n",
      "Time elapsed 0.7152393261591593 minutes\n",
      "Epoch 190, training loss 0.986388, accuracy 0.640625\n",
      "Validation accuracy 0.627083\n",
      "Time elapsed 0.7189223845799764 minutes\n",
      "Epoch 191, training loss 0.980116, accuracy 0.656250\n",
      "Validation accuracy 0.595833\n",
      "Time elapsed 0.722654390335083 minutes\n",
      "Epoch 192, training loss 1.109379, accuracy 0.562500\n",
      "Validation accuracy 0.614583\n",
      "Time elapsed 0.7262760639190674 minutes\n",
      "Epoch 193, training loss 1.210763, accuracy 0.515625\n",
      "Validation accuracy 0.604167\n",
      "Time elapsed 0.7298482060432434 minutes\n",
      "Epoch 194, training loss 1.037364, accuracy 0.687500\n",
      "Validation accuracy 0.600000\n",
      "Time elapsed 0.7341069142023723 minutes\n",
      "Epoch 195, training loss 0.989074, accuracy 0.718750\n",
      "Validation accuracy 0.605208\n",
      "Time elapsed 0.73768230676651 minutes\n",
      "Epoch 196, training loss 0.908569, accuracy 0.718750\n",
      "Validation accuracy 0.626042\n",
      "Time elapsed 0.7416854977607727 minutes\n",
      "Epoch 197, training loss 0.909341, accuracy 0.609375\n",
      "Validation accuracy 0.601042\n",
      "Time elapsed 0.7455546180407207 minutes\n",
      "Epoch 198, training loss 0.846545, accuracy 0.656250\n",
      "Validation accuracy 0.631250\n",
      "Time elapsed 0.749494445323944 minutes\n",
      "Epoch 199, training loss 0.928401, accuracy 0.609375\n",
      "Validation accuracy 0.593750\n",
      "Time elapsed 0.753174074490865 minutes\n",
      "Testing set accuracy 0.577148\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(SUMMARIES_DIR+'/train',\n",
    "                                     sess.graph)\n",
    "validation_writer = tf.summary.FileWriter(SUMMARIES_DIR+'/validation')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "cifar10.reset()\n",
    "print(\"Trainable variables\")\n",
    "for n in tf.trainable_variables():\n",
    "    print(n.name)\n",
    "\n",
    "epochs = 200\n",
    "mean_gradients = np.zeros([len(tf.trainable_variables()), epochs])\n",
    "std_gradients = np.zeros([len(tf.trainable_variables()), epochs])\n",
    "\n",
    "t_i = time.time()\n",
    "n_batches = cifar10.n_batches\n",
    "while cifar10.getEpoch() < epochs:\n",
    "    epoch = cifar10.getEpoch()\n",
    "    batch, batch_idx = cifar10.nextBatch()\n",
    "    batch_data = batch[0]\n",
    "    batch_labels = batch[1]\n",
    "    \n",
    "    # just a training iteration\n",
    "    _ = sess.run(train_step,\n",
    "                feed_dict={\n",
    "            model_input: batch_data,\n",
    "            target: batch_labels,\n",
    "            keep_prob: 0.5\n",
    "        })\n",
    "    \n",
    "    step = batch_idx+epoch*n_batches\n",
    "    \n",
    "    # Write training summary\n",
    "    if step%50==0:\n",
    "        summary = sess.run(merged,\n",
    "                          feed_dict={\n",
    "                model_input: batch_data,\n",
    "                target: batch_labels,\n",
    "                keep_prob: 0.5 # set to 1.0 at inference time\n",
    "            })\n",
    "        train_writer.add_summary(summary, step)\n",
    "        \n",
    "    # gradient (by layer) statistics over last training batch & validation summary\n",
    "    if batch_idx==0:\n",
    "        loss, acc, grads = sess.run((cross_entropy, accuracy, grads_vars), \n",
    "                      feed_dict={\n",
    "            model_input: batch_data,\n",
    "            target: batch_labels,\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "\n",
    "        for layer in range(len(tf.trainable_variables())):\n",
    "            mean_gradients[layer, epoch] = np.mean(np.abs(grads[layer][0]))\n",
    "            std_gradients[layer, epoch] = np.std(np.abs(grads[layer][0]))\n",
    "        print(\"Epoch %d, training loss %f, accuracy %f\" % (epoch, loss, acc))\n",
    "        \n",
    "        summary, validation_accuracy = validate()\n",
    "        validation_writer.add_summary(summary, step)\n",
    "        print(\"Validation accuracy %f\" % validation_accuracy)\n",
    "        print(\"Time elapsed\", (time.time()-t_i)/60.0, \"minutes\")\n",
    "train_writer.flush()\n",
    "validation_writer.flush()\n",
    "test_acc = test()\n",
    "print(\"Testing set accuracy %f\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting gradients\n",
    "n_layers = len(tf.trainable_variables()) // 2\n",
    "x = np.arange(epochs)\n",
    "i = 0\n",
    "plt.figure()\n",
    "while i < n_layers*2:\n",
    "    plt.errorbar(x,mean_gradients[i,:],std_gradients[i,:])\n",
    "    i = i + 2\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Gradient')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Weights Gradient by Layer')\n",
    "plt.legend([\"conv1\",\"conv2\",\"fc1\",\"fc2\"][-n_layers:])\n",
    "plt.xlim(-0.2, epochs)\n",
    "plt.show()\n",
    "i = 1\n",
    "plt.figure()\n",
    "while i < n_layers*2:\n",
    "    plt.errorbar(x,mean_gradients[i,:],std_gradients[i,:])\n",
    "    i = i + 2\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Gradient')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Biases Gradient by Layer')\n",
    "plt.legend([\"conv1\",\"conv2\",\"fc1\",\"fc2\"][-n_layers:])\n",
    "plt.xlim(-0.2, epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(targets, outputs):\n",
    "    '''Returns a confusion matrix. Both targets and outputs\n",
    "    should be 1-D arrays of zeros and ones.'''\n",
    "    encoded_data = 2*targets+outputs  # Map targets and outputs to {0, 1, 2, 3}\n",
    "    TN = np.sum(encoded_data == 0)  # True negatives\n",
    "    FP = np.sum(encoded_data == 1)  # False positives\n",
    "    FN = np.sum(encoded_data == 2)  # False negatives\n",
    "    TP = np.sum(encoded_data == 3)  # True positives\n",
    "    return ((TP, FP), (FN, TN))\n",
    "\n",
    "def roc_curve(targets, outputs):\n",
    "    '''Returns a ROC curve. Outputs should be in range 0-1\n",
    "    in order to move the threshold.'''\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for threshold in np.linspace(0, 1, 1000):\n",
    "        outputs_with_threshold = (outputs > threshold).astype(np.float)\n",
    "        ((TP, FP), (FN, TN)) = confusion_matrix(\n",
    "            targets, \n",
    "            outputs_with_threshold)\n",
    "        tpr.append(TP/(TP+FN))\n",
    "        fpr.append(FP/(FP+TN))\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "accs = sess.run(accuracy,\n",
    "             feed_dict={\n",
    "            model_input: cifar10.training_data,\n",
    "                       target: cifar10.training_labels,\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "\n",
    "accs = np.asarray(accs)\n",
    "[[VN,FP],[FN,VP]] = confusion_matrix(\n",
    "    accs,\n",
    "    (accs>0.5).astype(np.float))\n",
    "print('VP: %d, VN: %d, FP: %d, FN: %d' %(VP,VN,FP,FN))\n",
    "print('Porcentaje de clasificaciones correctas: %%%f' %(100.0*(VP+VN)/(VP+VN+FP+FN)))\n",
    "print('Precision: %%%f' %(100.0*VP/(VP+FP)))\n",
    "print('Recall: %%%f' %(100.0*VP/(VP+FN)))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
