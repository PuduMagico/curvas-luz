{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "\n",
    "from parser_EB import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "tf.set_random_seed(1)\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "batch_size = 64\n",
    "cifar10 = CIFAR10(batch_size=batch_size, validation_proportion=0.1, augment_data=False, file='data_EB.csv')\n",
    "\n",
    "SUMMARIES_DIR = './summaries/convnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model blocks\n",
    "def conv_layer(input_tensor, kernel_shape, layer_name):\n",
    "    # input_tensor b01c\n",
    "    # kernel_shape 01-in-out\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "                               initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    biases = tf.get_variable(\"biases\", [kernel_shape[3]],\n",
    "                             initializer=tf.constant_initializer(0.05))\n",
    "    \n",
    "    tf.summary.histogram(layer_name + \"/weights\", weights)\n",
    "    tf.summary.histogram(layer_name + \"/biases\", biases)\n",
    "    \n",
    "    # Other options are to use He et. al init. for weights and 0.01 \n",
    "    # to init. biases.\n",
    "    conv = tf.nn.conv2d(input_tensor, weights, \n",
    "                       strides = [1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "def fc_layer(input_tensor, weights_shape, layer_name):\n",
    "    # weights_shape in-out\n",
    "    weights = tf.get_variable(\"weights\", weights_shape,\n",
    "                              initializer = tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(\"biases\", [weights_shape[1]],\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "    tf.summary.histogram(layer_name + \"/weights\", weights)\n",
    "    tf.summary.histogram(layer_name + \"/biases\", biases)\n",
    "    mult_out = tf.matmul(input_tensor, weights)\n",
    "    return tf.nn.relu(mult_out+biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_input = tf.placeholder(tf.float32, name='model_input', \n",
    "                             shape=(batch_size,1,200,1))\n",
    "tf.summary.image('input', model_input, 10)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='dropout_prob', shape=())\n",
    "\n",
    "target = tf.placeholder(tf.float32, name='target', shape=(batch_size, 4))\n",
    "\n",
    "# First convolution layer\n",
    "layer_name = 'conv1'\n",
    "with tf.variable_scope(layer_name):\n",
    "    conv1_out = conv_layer(model_input, [1, 3, 1, 20], layer_name)\n",
    "# First pooling layer\n",
    "with tf.name_scope('pool1'):\n",
    "    pool1_out = tf.nn.avg_pool(conv1_out, ksize=[1, 2, 2, 1],\n",
    "                strides=[1, 2, 2, 1], padding='SAME',\n",
    "                name='pool1')\n",
    "    \n",
    "\n",
    "# Second convolution layer\n",
    "layer_name = 'conv2'\n",
    "with tf.variable_scope(layer_name):\n",
    "    conv2_out = conv_layer(pool1_out, [1, 3, 20, 20], layer_name)\n",
    "# Second pooling layer\n",
    "with tf.name_scope('pool2'):\n",
    "    pool2_out = tf.nn.avg_pool(conv2_out, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME',\n",
    "                            name='pool2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,dim3,dim4 = pool2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2_out_flat = tf.reshape(pool2_out, [-1, 1*dim3.value*dim4.value], name='pool2_flat')\n",
    "# First fully connected layer\n",
    "layer_name = 'fc1'\n",
    "with tf.variable_scope(layer_name):\n",
    "    fc1_out = fc_layer(pool2_out_flat, [1*dim3.value*dim4.value, 500], layer_name)\n",
    "fc1_out_drop = tf.nn.dropout(fc1_out, keep_prob)\n",
    "\n",
    "# Second fully connected layer\n",
    "layer_name = 'fc2'\n",
    "with tf.variable_scope(layer_name):\n",
    "    fc2_out = fc_layer(fc1_out_drop, [500, 250], layer_name)\n",
    "fc2_out_drop = tf.nn.dropout(fc2_out, keep_prob)\n",
    "\n",
    "\n",
    "# Third fully connected layer\n",
    "layer_name = 'fc3'\n",
    "with tf.variable_scope(layer_name):\n",
    "    fc3_out = fc_layer(fc2_out_drop, [250,4], layer_name)\n",
    "model_output = fc3_out\n",
    "\n",
    "\n",
    "with tf.name_scope('loss_function'):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=model_output, labels=target,\n",
    "                                           name='cross_entropy'))\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    grads_vars = optimizer.compute_gradients(cross_entropy)\n",
    "    optimizer.apply_gradients(grads_vars)\n",
    "    train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# Metrics\n",
    "correct_prediction = tf.equal(tf.argmax(model_output, 1),\n",
    "                             tf.argmax(target, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Useful training functions\n",
    "def validate():\n",
    "    batches = cifar10.getValidationSet(asBatches=True)\n",
    "    accs = []\n",
    "    for batch in batches:\n",
    "        data, labels = batch\n",
    "        acc = sess.run(accuracy,\n",
    "                       feed_dict={\n",
    "                model_input: data,\n",
    "                target: labels,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "        accs.append(acc)\n",
    "    mean_acc = np.array(accs).mean()\n",
    "    summary = sess.run(merged,\n",
    "                       feed_dict={\n",
    "                model_input: data,\n",
    "                target: labels,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "    return summary, mean_acc\n",
    "def test():\n",
    "    batches = cifar10.getTestSet(asBatches=True)\n",
    "    accs = []\n",
    "    for batch in batches:\n",
    "        data, labels = batch\n",
    "        acc = sess.run(accuracy,\n",
    "                       feed_dict={\n",
    "                model_input: data,\n",
    "                target: labels,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "        accs.append(acc)\n",
    "    mean_acc = np.array(accs).mean()\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable variables\n",
      "conv1/weights:0\n",
      "conv1/biases:0\n",
      "conv2/weights:0\n",
      "conv2/biases:0\n",
      "fc1/weights:0\n",
      "fc1/biases:0\n",
      "fc2/weights:0\n",
      "fc2/biases:0\n",
      "fc3/weights:0\n",
      "fc3/biases:0\n",
      "Epoch 0, training loss 1.259977, accuracy 0.484375\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.002742131551106771 minutes\n",
      "Epoch 1, training loss 1.012172, accuracy 0.500000\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.015562578042348226 minutes\n",
      "Epoch 2, training loss 0.994994, accuracy 0.500000\n",
      "Validation accuracy 0.481771\n",
      "Time elapsed 0.029232112566630046 minutes\n",
      "Epoch 3, training loss 1.070069, accuracy 0.437500\n",
      "Validation accuracy 0.440104\n",
      "Time elapsed 0.0421108603477478 minutes\n",
      "Epoch 4, training loss 0.942939, accuracy 0.437500\n",
      "Validation accuracy 0.440104\n",
      "Time elapsed 0.05629561344782511 minutes\n",
      "Epoch 5, training loss 1.028430, accuracy 0.296875\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.06960565249125163 minutes\n",
      "Epoch 6, training loss 0.893241, accuracy 0.484375\n",
      "Validation accuracy 0.440104\n",
      "Time elapsed 0.08302467664082845 minutes\n",
      "Epoch 7, training loss 0.886343, accuracy 0.390625\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.09612067540486653 minutes\n",
      "Epoch 8, training loss 0.857571, accuracy 0.375000\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.10971595446268717 minutes\n",
      "Epoch 9, training loss 0.895175, accuracy 0.484375\n",
      "Validation accuracy 0.440104\n",
      "Time elapsed 0.12240010102589925 minutes\n",
      "Epoch 10, training loss 0.886095, accuracy 0.500000\n",
      "Validation accuracy 0.440104\n",
      "Time elapsed 0.13642576535542805 minutes\n",
      "Epoch 11, training loss 0.939417, accuracy 0.453125\n",
      "Validation accuracy 0.468750\n",
      "Time elapsed 0.1493520498275757 minutes\n",
      "Epoch 12, training loss 0.902187, accuracy 0.375000\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.1633552034695943 minutes\n",
      "Epoch 13, training loss 0.917394, accuracy 0.484375\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.1766795555750529 minutes\n",
      "Epoch 14, training loss 1.006327, accuracy 0.468750\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.1895086129506429 minutes\n",
      "Epoch 15, training loss 0.935383, accuracy 0.546875\n",
      "Validation accuracy 0.432292\n",
      "Time elapsed 0.20314837296803792 minutes\n",
      "Epoch 16, training loss 0.902152, accuracy 0.453125\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.21660019954045615 minutes\n",
      "Epoch 17, training loss 0.912824, accuracy 0.421875\n",
      "Validation accuracy 0.432292\n",
      "Time elapsed 0.23025603691736857 minutes\n",
      "Epoch 18, training loss 0.936095, accuracy 0.406250\n",
      "Validation accuracy 0.479167\n",
      "Time elapsed 0.24340105056762695 minutes\n",
      "Epoch 19, training loss 0.897896, accuracy 0.390625\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.257551364103953 minutes\n",
      "Epoch 20, training loss 0.809210, accuracy 0.375000\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.2709152301152547 minutes\n",
      "Epoch 21, training loss 0.917138, accuracy 0.421875\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.284811528523763 minutes\n",
      "Epoch 22, training loss 0.922855, accuracy 0.546875\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.2980253577232361 minutes\n",
      "Epoch 23, training loss 0.812791, accuracy 0.515625\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.3107949693997701 minutes\n",
      "Epoch 24, training loss 0.918857, accuracy 0.484375\n",
      "Validation accuracy 0.510417\n",
      "Time elapsed 0.32409663995107013 minutes\n",
      "Epoch 25, training loss 0.982231, accuracy 0.343750\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.33709898789723713 minutes\n",
      "Epoch 26, training loss 0.965617, accuracy 0.390625\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.35025952259699505 minutes\n",
      "Epoch 27, training loss 0.956382, accuracy 0.421875\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.3629923899968465 minutes\n",
      "Epoch 28, training loss 1.010190, accuracy 0.421875\n",
      "Validation accuracy 0.437500\n",
      "Time elapsed 0.3760684053103129 minutes\n",
      "Epoch 29, training loss 0.907125, accuracy 0.484375\n",
      "Validation accuracy 0.429688\n",
      "Time elapsed 0.3891053358713786 minutes\n",
      "Epoch 30, training loss 0.861125, accuracy 0.453125\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.4032737056414286 minutes\n",
      "Epoch 31, training loss 0.823224, accuracy 0.531250\n",
      "Validation accuracy 0.468750\n",
      "Time elapsed 0.41603897412618 minutes\n",
      "Epoch 32, training loss 0.930410, accuracy 0.453125\n",
      "Validation accuracy 0.513021\n",
      "Time elapsed 0.4301722884178162 minutes\n",
      "Epoch 33, training loss 0.880229, accuracy 0.453125\n",
      "Validation accuracy 0.429688\n",
      "Time elapsed 0.4433071215947469 minutes\n",
      "Epoch 34, training loss 0.810125, accuracy 0.500000\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.45774393479029335 minutes\n",
      "Epoch 35, training loss 0.862198, accuracy 0.515625\n",
      "Validation accuracy 0.429688\n",
      "Time elapsed 0.47076818148295085 minutes\n",
      "Epoch 36, training loss 0.897794, accuracy 0.562500\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.48378959894180296 minutes\n",
      "Epoch 37, training loss 0.924198, accuracy 0.406250\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 0.49730396270751953 minutes\n",
      "Epoch 38, training loss 1.001048, accuracy 0.390625\n",
      "Validation accuracy 0.471354\n",
      "Time elapsed 0.5102032820383707 minutes\n",
      "Epoch 39, training loss 0.877440, accuracy 0.328125\n",
      "Validation accuracy 0.466146\n",
      "Time elapsed 0.522995400428772 minutes\n",
      "Epoch 40, training loss 0.831773, accuracy 0.484375\n",
      "Validation accuracy 0.471354\n",
      "Time elapsed 0.5363271395365398 minutes\n",
      "Epoch 41, training loss 0.837717, accuracy 0.531250\n",
      "Validation accuracy 0.471354\n",
      "Time elapsed 0.5498241186141968 minutes\n",
      "Epoch 42, training loss 0.963804, accuracy 0.437500\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.5632213513056438 minutes\n",
      "Epoch 43, training loss 0.940645, accuracy 0.406250\n",
      "Validation accuracy 0.429688\n",
      "Time elapsed 0.5760503967603048 minutes\n",
      "Epoch 44, training loss 0.885357, accuracy 0.562500\n",
      "Validation accuracy 0.466146\n",
      "Time elapsed 0.5896637201309204 minutes\n",
      "Epoch 45, training loss 0.841271, accuracy 0.453125\n",
      "Validation accuracy 0.432292\n",
      "Time elapsed 0.6029836575190226 minutes\n",
      "Epoch 46, training loss 0.916764, accuracy 0.500000\n",
      "Validation accuracy 0.437500\n",
      "Time elapsed 0.6156551718711853 minutes\n",
      "Epoch 47, training loss 0.963988, accuracy 0.406250\n",
      "Validation accuracy 0.481771\n",
      "Time elapsed 0.6296749909718832 minutes\n",
      "Epoch 48, training loss 0.893531, accuracy 0.546875\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.6428771098454793 minutes\n",
      "Epoch 49, training loss 0.823456, accuracy 0.500000\n",
      "Validation accuracy 0.471354\n",
      "Time elapsed 0.6573578079541524 minutes\n",
      "Epoch 50, training loss 0.823926, accuracy 0.500000\n",
      "Validation accuracy 0.484375\n",
      "Time elapsed 0.6703314344088237 minutes\n",
      "Epoch 51, training loss 0.911178, accuracy 0.546875\n",
      "Validation accuracy 0.463542\n",
      "Time elapsed 0.6832774599393209 minutes\n",
      "Epoch 52, training loss 0.970979, accuracy 0.515625\n",
      "Validation accuracy 0.510417\n",
      "Time elapsed 0.6961760520935059 minutes\n",
      "Epoch 53, training loss 0.961538, accuracy 0.437500\n",
      "Validation accuracy 0.500000\n",
      "Time elapsed 0.7109140396118164 minutes\n",
      "Epoch 54, training loss 0.816072, accuracy 0.484375\n",
      "Validation accuracy 0.489583\n",
      "Time elapsed 0.7241104046503702 minutes\n",
      "Epoch 55, training loss 0.974408, accuracy 0.484375\n",
      "Validation accuracy 0.471354\n",
      "Time elapsed 0.7372434298197429 minutes\n",
      "Epoch 56, training loss 0.991861, accuracy 0.546875\n",
      "Validation accuracy 0.494792\n",
      "Time elapsed 0.750394880771637 minutes\n",
      "Epoch 57, training loss 1.019112, accuracy 0.421875\n",
      "Validation accuracy 0.494792\n",
      "Time elapsed 0.7638994137446086 minutes\n",
      "Epoch 58, training loss 0.881175, accuracy 0.406250\n",
      "Validation accuracy 0.492188\n",
      "Time elapsed 0.7769229253133138 minutes\n",
      "Epoch 59, training loss 0.912906, accuracy 0.468750\n",
      "Validation accuracy 0.486979\n",
      "Time elapsed 0.7901986718177796 minutes\n",
      "Epoch 60, training loss 0.779325, accuracy 0.562500\n",
      "Validation accuracy 0.505208\n",
      "Time elapsed 0.804008420308431 minutes\n",
      "Epoch 61, training loss 0.948749, accuracy 0.453125\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.816955029964447 minutes\n",
      "Epoch 62, training loss 0.833894, accuracy 0.593750\n",
      "Validation accuracy 0.481771\n",
      "Time elapsed 0.8302694837252299 minutes\n",
      "Epoch 63, training loss 0.887516, accuracy 0.484375\n",
      "Validation accuracy 0.466146\n",
      "Time elapsed 0.8433315714200338 minutes\n",
      "Epoch 64, training loss 0.905290, accuracy 0.515625\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 0.8566732843716939 minutes\n",
      "Epoch 65, training loss 0.844769, accuracy 0.453125\n",
      "Validation accuracy 0.489583\n",
      "Time elapsed 0.8697813510894775 minutes\n",
      "Epoch 66, training loss 0.833951, accuracy 0.593750\n",
      "Validation accuracy 0.458333\n",
      "Time elapsed 0.8823031385739645 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, training loss 0.943524, accuracy 0.437500\n",
      "Validation accuracy 0.510417\n",
      "Time elapsed 0.8953119834264119 minutes\n",
      "Epoch 68, training loss 0.931236, accuracy 0.375000\n",
      "Validation accuracy 0.492188\n",
      "Time elapsed 0.908059827486674 minutes\n",
      "Epoch 69, training loss 0.861374, accuracy 0.515625\n",
      "Validation accuracy 0.497396\n",
      "Time elapsed 0.9231085419654846 minutes\n",
      "Epoch 70, training loss 0.976557, accuracy 0.437500\n",
      "Validation accuracy 0.505208\n",
      "Time elapsed 0.9377431352933248 minutes\n",
      "Epoch 71, training loss 0.859173, accuracy 0.484375\n",
      "Validation accuracy 0.429688\n",
      "Time elapsed 0.9513580083847046 minutes\n",
      "Epoch 72, training loss 0.864198, accuracy 0.578125\n",
      "Validation accuracy 0.458333\n",
      "Time elapsed 0.9653456290562947 minutes\n",
      "Epoch 73, training loss 0.775513, accuracy 0.453125\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.9788402636845907 minutes\n",
      "Epoch 74, training loss 0.906998, accuracy 0.453125\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 0.99220898548762 minutes\n",
      "Epoch 75, training loss 0.948173, accuracy 0.453125\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 1.0052002668380737 minutes\n",
      "Epoch 76, training loss 0.873516, accuracy 0.562500\n",
      "Validation accuracy 0.510417\n",
      "Time elapsed 1.0188071846961975 minutes\n",
      "Epoch 77, training loss 0.904970, accuracy 0.578125\n",
      "Validation accuracy 0.460938\n",
      "Time elapsed 1.0314759612083435 minutes\n",
      "Epoch 78, training loss 0.882521, accuracy 0.453125\n",
      "Validation accuracy 0.471354\n",
      "Time elapsed 1.044381284713745 minutes\n",
      "Epoch 79, training loss 0.841976, accuracy 0.500000\n",
      "Validation accuracy 0.492188\n",
      "Time elapsed 1.05850594441096 minutes\n",
      "Epoch 80, training loss 0.908700, accuracy 0.515625\n",
      "Validation accuracy 0.437500\n",
      "Time elapsed 1.0719091812769572 minutes\n",
      "Epoch 81, training loss 0.899206, accuracy 0.531250\n",
      "Validation accuracy 0.479167\n",
      "Time elapsed 1.0853931148846945 minutes\n",
      "Epoch 82, training loss 0.875016, accuracy 0.515625\n",
      "Validation accuracy 0.453125\n",
      "Time elapsed 1.0985546986262003 minutes\n",
      "Epoch 83, training loss 0.818112, accuracy 0.421875\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 1.1120375752449037 minutes\n",
      "Epoch 84, training loss 1.014658, accuracy 0.484375\n",
      "Validation accuracy 0.505208\n",
      "Time elapsed 1.126441446940104 minutes\n",
      "Epoch 85, training loss 1.090283, accuracy 0.312500\n",
      "Validation accuracy 0.479167\n",
      "Time elapsed 1.1404649178187052 minutes\n",
      "Epoch 86, training loss 1.019787, accuracy 0.468750\n",
      "Validation accuracy 0.489583\n",
      "Time elapsed 1.1546710054079692 minutes\n",
      "Epoch 87, training loss 0.910572, accuracy 0.468750\n",
      "Validation accuracy 0.486979\n",
      "Time elapsed 1.168676487604777 minutes\n",
      "Epoch 88, training loss 0.914994, accuracy 0.421875\n",
      "Validation accuracy 0.455729\n",
      "Time elapsed 1.1815603057543436 minutes\n",
      "Epoch 89, training loss 0.931134, accuracy 0.546875\n",
      "Validation accuracy 0.497396\n",
      "Time elapsed 1.1942161242167155 minutes\n",
      "Epoch 90, training loss 0.974604, accuracy 0.484375\n",
      "Validation accuracy 0.450521\n",
      "Time elapsed 1.2074457009633381 minutes\n",
      "Epoch 91, training loss 0.937365, accuracy 0.468750\n",
      "Validation accuracy 0.476562\n",
      "Time elapsed 1.2199964483579 minutes\n",
      "Epoch 92, training loss 0.814023, accuracy 0.484375\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 1.23317391872406 minutes\n",
      "Epoch 93, training loss 0.877667, accuracy 0.484375\n",
      "Validation accuracy 0.500000\n",
      "Time elapsed 1.247071663538615 minutes\n",
      "Epoch 94, training loss 0.863315, accuracy 0.562500\n",
      "Validation accuracy 0.497396\n",
      "Time elapsed 1.2619019548098247 minutes\n",
      "Epoch 95, training loss 1.009914, accuracy 0.437500\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 1.2759532054265341 minutes\n",
      "Epoch 96, training loss 0.909225, accuracy 0.500000\n",
      "Validation accuracy 0.486979\n",
      "Time elapsed 1.289915148417155 minutes\n",
      "Epoch 97, training loss 0.899473, accuracy 0.406250\n",
      "Validation accuracy 0.486979\n",
      "Time elapsed 1.3037908871968586 minutes\n",
      "Epoch 98, training loss 0.867263, accuracy 0.390625\n",
      "Validation accuracy 0.500000\n",
      "Time elapsed 1.317192002137502 minutes\n",
      "Epoch 99, training loss 0.942371, accuracy 0.390625\n",
      "Validation accuracy 0.492188\n",
      "Time elapsed 1.3312003095944722 minutes\n",
      "Epoch 100, training loss 0.963854, accuracy 0.437500\n",
      "Validation accuracy 0.434896\n",
      "Time elapsed 1.3448484261830649 minutes\n",
      "Epoch 101, training loss 1.007701, accuracy 0.421875\n",
      "Validation accuracy 0.492188\n",
      "Time elapsed 1.3575446526209514 minutes\n",
      "Epoch 102, training loss 0.986308, accuracy 0.484375\n",
      "Validation accuracy 0.505208\n",
      "Time elapsed 1.3707247853279114 minutes\n",
      "Epoch 103, training loss 0.910396, accuracy 0.500000\n",
      "Validation accuracy 0.484375\n",
      "Time elapsed 1.3849107344945273 minutes\n",
      "Epoch 104, training loss 0.825552, accuracy 0.625000\n",
      "Validation accuracy 0.513021\n",
      "Time elapsed 1.3984164158503214 minutes\n",
      "Epoch 105, training loss 0.901124, accuracy 0.390625\n",
      "Validation accuracy 0.515625\n",
      "Time elapsed 1.4122013727823892 minutes\n",
      "Epoch 106, training loss 0.992089, accuracy 0.375000\n",
      "Validation accuracy 0.442708\n",
      "Time elapsed 1.4257944504419962 minutes\n",
      "Epoch 107, training loss 0.845920, accuracy 0.421875\n",
      "Validation accuracy 0.492188\n",
      "Time elapsed 1.4396687110265096 minutes\n",
      "Epoch 108, training loss 0.930076, accuracy 0.343750\n",
      "Validation accuracy 0.479167\n",
      "Time elapsed 1.453699525197347 minutes\n",
      "Epoch 109, training loss 0.857759, accuracy 0.484375\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 1.4668619871139525 minutes\n",
      "Epoch 110, training loss 0.966790, accuracy 0.468750\n",
      "Validation accuracy 0.513021\n",
      "Time elapsed 1.4801144123077392 minutes\n",
      "Epoch 111, training loss 0.886522, accuracy 0.468750\n",
      "Validation accuracy 0.500000\n",
      "Time elapsed 1.4934740861256917 minutes\n",
      "Epoch 112, training loss 0.836510, accuracy 0.515625\n",
      "Validation accuracy 0.513021\n",
      "Time elapsed 1.507195564111074 minutes\n",
      "Epoch 113, training loss 0.881743, accuracy 0.500000\n",
      "Validation accuracy 0.463542\n",
      "Time elapsed 1.5209891676902771 minutes\n",
      "Epoch 114, training loss 0.828743, accuracy 0.531250\n",
      "Validation accuracy 0.479167\n",
      "Time elapsed 1.5336503624916076 minutes\n",
      "Epoch 115, training loss 0.883983, accuracy 0.390625\n",
      "Validation accuracy 0.450521\n",
      "Time elapsed 1.5469064712524414 minutes\n",
      "Epoch 116, training loss 0.874843, accuracy 0.421875\n",
      "Validation accuracy 0.489583\n",
      "Time elapsed 1.559454039732615 minutes\n",
      "Epoch 117, training loss 0.891946, accuracy 0.406250\n",
      "Validation accuracy 0.440104\n",
      "Time elapsed 1.5731538971265158 minutes\n",
      "Epoch 118, training loss 0.934772, accuracy 0.484375\n",
      "Validation accuracy 0.440104\n",
      "Time elapsed 1.5871349851290384 minutes\n",
      "Epoch 119, training loss 0.782174, accuracy 0.453125\n",
      "Validation accuracy 0.513021\n",
      "Time elapsed 1.6014059464136758 minutes\n",
      "Epoch 120, training loss 0.930896, accuracy 0.453125\n",
      "Validation accuracy 0.489583\n",
      "Time elapsed 1.6155832290649415 minutes\n",
      "Epoch 121, training loss 0.977479, accuracy 0.390625\n",
      "Validation accuracy 0.437500\n",
      "Time elapsed 1.6296640475591024 minutes\n",
      "Epoch 122, training loss 0.862563, accuracy 0.515625\n",
      "Validation accuracy 0.489583\n",
      "Time elapsed 1.6430233081181844 minutes\n",
      "Epoch 123, training loss 0.891958, accuracy 0.453125\n",
      "Validation accuracy 0.460938\n",
      "Time elapsed 1.655923028786977 minutes\n",
      "Epoch 124, training loss 0.844101, accuracy 0.500000\n",
      "Validation accuracy 0.466146\n",
      "Time elapsed 1.6696266372998556 minutes\n",
      "Epoch 125, training loss 0.910191, accuracy 0.343750\n",
      "Validation accuracy 0.492188\n",
      "Time elapsed 1.682761279741923 minutes\n",
      "Epoch 126, training loss 1.041592, accuracy 0.406250\n",
      "Validation accuracy 0.473958\n",
      "Time elapsed 1.6960293690363566 minutes\n",
      "Epoch 127, training loss 0.974481, accuracy 0.406250\n",
      "Validation accuracy 0.515625\n",
      "Time elapsed 1.709611423810323 minutes\n",
      "Epoch 128, training loss 0.886714, accuracy 0.546875\n",
      "Validation accuracy 0.500000\n",
      "Time elapsed 1.722815958658854 minutes\n",
      "Epoch 129, training loss 1.028835, accuracy 0.421875\n",
      "Validation accuracy 0.471354\n",
      "Time elapsed 1.7361379782358806 minutes\n",
      "Epoch 130, training loss 0.795905, accuracy 0.468750\n",
      "Validation accuracy 0.468750\n",
      "Time elapsed 1.7509359836578369 minutes\n",
      "Epoch 131, training loss 0.868201, accuracy 0.484375\n",
      "Validation accuracy 0.481771\n",
      "Time elapsed 1.7639535824457804 minutes\n",
      "Epoch 132, training loss 0.889290, accuracy 0.578125\n",
      "Validation accuracy 0.520833\n",
      "Time elapsed 1.7782496770222982 minutes\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(SUMMARIES_DIR+'/train',\n",
    "                                     sess.graph)\n",
    "validation_writer = tf.summary.FileWriter(SUMMARIES_DIR+'/validation')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "cifar10.reset()\n",
    "print(\"Trainable variables\")\n",
    "for n in tf.trainable_variables():\n",
    "    print(n.name)\n",
    "\n",
    "epochs = 200\n",
    "mean_gradients = np.zeros([len(tf.trainable_variables()), epochs])\n",
    "std_gradients = np.zeros([len(tf.trainable_variables()), epochs])\n",
    "\n",
    "t_i = time.time()\n",
    "n_batches = cifar10.n_batches\n",
    "while cifar10.getEpoch() < epochs:\n",
    "    epoch = cifar10.getEpoch()\n",
    "    batch, batch_idx = cifar10.nextBatch()\n",
    "    batch_data = batch[0]\n",
    "    batch_labels = batch[1]\n",
    "    \n",
    "    # just a training iteration\n",
    "    _ = sess.run(train_step,\n",
    "                feed_dict={\n",
    "            model_input: batch_data,\n",
    "            target: batch_labels,\n",
    "            keep_prob: 0.5\n",
    "        })\n",
    "    \n",
    "    step = batch_idx+epoch*n_batches\n",
    "    \n",
    "    # Write training summary\n",
    "    if step%50==0:\n",
    "        summary = sess.run(merged,\n",
    "                          feed_dict={\n",
    "                model_input: batch_data,\n",
    "                target: batch_labels,\n",
    "                keep_prob: 0.5 # set to 1.0 at inference time\n",
    "            })\n",
    "        train_writer.add_summary(summary, step)\n",
    "        \n",
    "    # gradient (by layer) statistics over last training batch & validation summary\n",
    "    if batch_idx==0:\n",
    "        loss, acc, grads = sess.run((cross_entropy, accuracy, grads_vars), \n",
    "                      feed_dict={\n",
    "            model_input: batch_data,\n",
    "            target: batch_labels,\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "\n",
    "        for layer in range(len(tf.trainable_variables())):\n",
    "            mean_gradients[layer, epoch] = np.mean(np.abs(grads[layer][0]))\n",
    "            std_gradients[layer, epoch] = np.std(np.abs(grads[layer][0]))\n",
    "        print(\"Epoch %d, training loss %f, accuracy %f\" % (epoch, loss, acc))\n",
    "        \n",
    "        summary, validation_accuracy = validate()\n",
    "        validation_writer.add_summary(summary, step)\n",
    "        print(\"Validation accuracy %f\" % validation_accuracy)\n",
    "        print(\"Time elapsed\", (time.time()-t_i)/60.0, \"minutes\")\n",
    "train_writer.flush()\n",
    "validation_writer.flush()\n",
    "test_acc = test()\n",
    "print(\"Testing set accuracy %f\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting gradients\n",
    "n_layers = len(tf.trainable_variables()) // 2\n",
    "x = np.arange(epochs)\n",
    "i = 0\n",
    "plt.figure()\n",
    "while i < n_layers*2:\n",
    "    plt.errorbar(x,mean_gradients[i,:],std_gradients[i,:])\n",
    "    i = i + 2\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Gradient')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Weights Gradient by Layer')\n",
    "plt.legend([\"conv1\",\"conv2\",\"fc1\",\"fc2\"][-n_layers:])\n",
    "plt.xlim(-0.2, epochs)\n",
    "plt.show()\n",
    "i = 1\n",
    "plt.figure()\n",
    "while i < n_layers*2:\n",
    "    plt.errorbar(x,mean_gradients[i,:],std_gradients[i,:])\n",
    "    i = i + 2\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Gradient')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Biases Gradient by Layer')\n",
    "plt.legend([\"conv1\",\"conv2\",\"fc1\",\"fc2\"][-n_layers:])\n",
    "plt.xlim(-0.2, epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(targets, outputs):\n",
    "    '''Returns a confusion matrix. Both targets and outputs\n",
    "    should be 1-D arrays of zeros and ones.'''\n",
    "    encoded_data = 2*targets+outputs  # Map targets and outputs to {0, 1, 2, 3}\n",
    "    TN = np.sum(encoded_data == 0)  # True negatives\n",
    "    FP = np.sum(encoded_data == 1)  # False positives\n",
    "    FN = np.sum(encoded_data == 2)  # False negatives\n",
    "    TP = np.sum(encoded_data == 3)  # True positives\n",
    "    return ((TP, FP), (FN, TN))\n",
    "\n",
    "def roc_curve(targets, outputs):\n",
    "    '''Returns a ROC curve. Outputs should be in range 0-1\n",
    "    in order to move the threshold.'''\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for threshold in np.linspace(0, 1, 1000):\n",
    "        outputs_with_threshold = (outputs > threshold).astype(np.float)\n",
    "        ((TP, FP), (FN, TN)) = confusion_matrix(\n",
    "            targets, \n",
    "            outputs_with_threshold)\n",
    "        tpr.append(TP/(TP+FN))\n",
    "        fpr.append(FP/(FP+TN))\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "accs = sess.run(accuracy,\n",
    "             feed_dict={\n",
    "            model_input: cifar10.training_data,\n",
    "                       target: cifar10.training_labels,\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "\n",
    "accs = np.asarray(accs)\n",
    "[[VN,FP],[FN,VP]] = confusion_matrix(\n",
    "    accs,\n",
    "    (accs>0.5).astype(np.float))\n",
    "print('VP: %d, VN: %d, FP: %d, FN: %d' %(VP,VN,FP,FN))\n",
    "print('Porcentaje de clasificaciones correctas: %%%f' %(100.0*(VP+VN)/(VP+VN+FP+FN)))\n",
    "print('Precision: %%%f' %(100.0*VP/(VP+FP)))\n",
    "print('Recall: %%%f' %(100.0*VP/(VP+FN)))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
